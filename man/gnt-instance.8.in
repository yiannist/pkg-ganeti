.\" This manpage has been automatically generated by docbook2man 
.\" from a DocBook document.  This tool can be found at:
.\" <http://shell.ipoline.com/~elmert/comp/docbook2X/> 
.\" Please send any bug reports, improvements, comments, patches, 
.\" etc. to Steve Cheng <steve@ggi-project.org>.
.TH "GNT-INSTANCE" "8" "16 July 2010" "ganeti 2.0" ""

.SH NAME
gnt-instance \- ganeti instance administration
.SH SYNOPSIS

\fBgnt-instance \fR \fBcommand\fR [ \fBarguments...\fR ]

.SH "DESCRIPTION"
.PP
The \fBgnt-instance\fR is used for instance
administration in the ganeti system.
.SH "COMMANDS"
.SS "CREATION/REMOVAL/QUERYING"
.SS "ADD"

\fBadd\fR
    \fB-t { diskless | file | plain | drbd }\fR
    { \fB--disk=\fIN\fB: { size=\fIVAL\fB | adopt=\fILV\fB },mode=\fIro|rw\fB\fR\fI ...\fR | \fB-s \fISIZE\fB\fR }
    [ \fB--no-ip-check\fR ] [ \fB--no-name-check\fR ] [ \fB--no-start\fR ] [ \fB--no-install\fR ]
    [ \fB--net=\fIN\fB [ :options\fI ...\fB ]\fR\fI ...\fR | \fB--no-nics\fR ]
    [ \fB-B \fIBEPARAMS\fB\fR ]
    [ \fB-H \fIHYPERVISOR\fB [ : option=\fIvalue\fB\fI ...\fB ]\fR ]
    [ \fB--file-storage-dir \fIdir_path\fB\fR ] [ \fB--file-driver { loop | blktap }\fR ]
    { \fB-n \fInode[:secondary-node]\fB\fR | \fB--iallocator \fIname\fB\fR }
    \fB-o \fIos-type\fB\fR
    [ \fB--submit\fR ]
    \fB\fIinstance\fB\fR

.PP
Creates a new instance on the specified host. The
\fIinstance\fR argument must be in DNS,
but depending on the bridge/routing setup, need not be in
the same network as the nodes in the cluster.
.PP
The \fBdisk\fR option specifies the parameters
for the disks of the instance. The numbering of disks starts
at zero, and at least one disk needs to be passed. For each
disk, either the size or the adoption source needs to be
given, and optionally the access mode (read-only or the
default of read-write) can also be specified.  The size is
interpreted (when no unit is given) in mebibytes. You can
also use one of the suffixes
m, g or
t to specificy the exact the units used;
these suffixes map to mebibytes, gibibytes and tebibytes.
.PP
When using the \fBadopt\fR key in the disk
definition, Ganeti will reuse those volumes (instead of
creating new ones) as the instance's disks. Ganeti will
rename these volumes to the standard format, and (without
installing the OS) will use them as-is for the
instance. This allows migrating instances from non-managed
mode (e.q. plain KVM with LVM) to being managed via
Ganeti. Note that this works only for the `plain' disk
template (see below for template details).
.PP
Alternatively, a single-disk instance can be created via the
\fB-s\fR option which takes a single argument,
the size of the disk. This is similar to the Ganeti 1.2
version (but will only create one disk).
.PP
The minimum disk specification is therefore
\fB--disk 0:size=20G\fR (or \fB-s
20G\fR when using the \fB-s\fR option),
and a three-disk instance can be specified as
\fB--disk 0:size=20G --disk 1:size=4G --disk
2:size=100G\fR\&.
.PP
The \fB--no-ip-check\fR skips the checks that are
done to see if the instance's IP is not already alive
(i.e. reachable from the master node).
.PP
The \fB--no-name-check\fR skips the check for the
instance name via the resolver (e.g. in DNS or /etc/hosts,
depending on your setup). Since the name check is used to
compute the IP address, if you pass this option you must
also pass the \fB--no-ip-check\fR option.
.PP
If you don't wat the instance to automatically start after
creation, this is possible via the
\fB--no-start\fR option. This will leave the
instance down until a subsequent \fBgnt-instance
start\fR command.
.PP
The NICs of the instances can be specified via the
\fB--net\fR option. By default, one NIC is
created for the instance, with a random MAC, and set
up according the the cluster level nic parameters.
Each NIC can take these parameters (all optional):
.TP
\fBmac\fR
either a value or GENERATE
to generate a new unique MAC
.TP
\fBip\fR
specifies the IP address assigned to the
instance from the Ganeti side (this is not necessarily
what the instance will use, but what the node expects
the instance to use)
.TP
\fBmode\fR
specifies the connection mode for this nic:
routed or bridged.
.TP
\fBlink\fR
in bridged mode specifies the bridge to attach
this NIC to, in routed mode it's intended to
differentiate between different routing tables/instance
groups (but the meaning is dependent on the network
script, see gnt-cluster(8) for more details)
Of these "mode" and "link" are nic parameters, and inherit their
default at cluster level.
.PP
Alternatively, if no network is desired for the instance, you
can prevent the default of one NIC with the
\fB--no-nics\fR option.
.PP
The \fB-o\fR options specifies the operating
system to be installed. The available operating systems can
be listed with \fBgnt-os
list\fR\&. Passing \fB--no-install\fR will
however skip the OS installation, allowing a manual import
if so desired. Note that the no-installation mode will
automatically disable the start-up of the instance (without
an OS, it most likely won't be able to start-up
successfully).
.PP
The \fB-B\fR option specifies the backend
parameters for the instance. If no such parameters are
specified, the values are inherited from the cluster. Possible
parameters are:
.TP
\fBmemory\fR
the memory size of the instance; as usual,
suffixes can be used to denote the unit, otherwise the
value is taken in mebibites
.TP
\fBvcpus\fR
the number of VCPUs to assign to the instance
(if this value makes sense for the hypervisor)
.TP
\fBauto_balance\fR
whether the instance is considered in the N+1
cluster checks (enough redundancy in the cluster to
survive a node failure)
.PP
The \fB-H\fR option specified the hypervisor to
use for the instance (must be one of the enabled hypervisors
on the cluster) and optionally custom parameters for this
instance. If not other options are used (i.e. the invocation
is just \fB-H
\fINAME\fB\fR) the instance
will inherit the cluster options. The defaults below show
the cluster defaults at cluster creation time.
.PP
The possible hypervisor options are as follows:
.TP
\fBboot_order\fR
Valid for the Xen HVM and KVM
hypervisors.

A string value denoting the boot order. This
has different meaning for the Xen HVM hypervisor and
for the KVM one.

For Xen HVM, The boot order is a string of letters
listing the boot devices, with valid device letters
being:
.RS
.TP
\fBa\fR
floppy drive
.TP
\fBc\fR
hard disk
.TP
\fBd\fR
CDROM drive
.TP
\fBn\fR
network boot (PXE)
.RE

The default is not to set an HVM boot order which is
interpreted as 'dc'.

For KVM the boot order is either
``cdrom'', ``disk'' or
``network''\&. Please note that older
versions of KVM couldn't netboot from virtio
interfaces. This has been fixed in more recent
versions and is confirmed to work at least with
qemu-kvm 0.11.1.
.TP
\fBcdrom_image_path\fR
Valid for the Xen HVM and KVM hypervisors.

The path to a CDROM image to attach to the
instance.
.TP
\fBnic_type\fR
Valid for the Xen HVM and KVM hypervisors.

This parameter determines the way the network cards
are presented to the instance. The possible options are:

rtl8139 (default for Xen HVM) (HVM & KVM)

ne2k_isa (HVM & KVM)

ne2k_pci (HVM & KVM)

i82551 (KVM)

i82557b (KVM)

i82559er (KVM)

pcnet (KVM)

e1000 (KVM)

paravirtual (default for KVM) (HVM & KVM)
.TP
\fBdisk_type\fR
Valid for the Xen HVM and KVM hypervisors.

This parameter determines the way the disks are
presented to the instance. The possible options are:

ioemu (default for HVM & KVM) (HVM & KVM)

ide (HVM & KVM)

scsi (KVM)

sd (KVM)

mtd (KVM)

pflash (KVM)
.TP
\fBvnc_bind_address\fR
Valid for the Xen HVM and KVM hypervisors.

Specifies the address that the VNC listener for
this instance should bind to. Valid values are IPv4
addresses. Use the address 0.0.0.0 to bind to all
available interfaces (this is the default) or specify
the address of one of the interfaces on the node to
restrict listening to that interface.
.TP
\fBvnc_tls\fR
Valid for the KVM hypervisor.

A boolean option that controls whether the
VNC connection is secured with TLS.
.TP
\fBvnc_x509_path\fR
Valid for the KVM hypervisor.

If \fBvnc_tls\fR is enabled, this
options specifies the path to the x509 certificate to
use.
.TP
\fBvnc_x509_verify\fR
Valid for the KVM hypervisor.
.TP
\fBacpi\fR
Valid for the Xen HVM and KVM hypervisors.

A boolean option that specifies if the hypervisor
should enable ACPI support for this instance. By
default, ACPI is disabled.
.TP
\fBpae\fR
Valid for the Xen HVM and KVM hypervisors.

A boolean option that specifies if the hypervisor
should enabled PAE support for this instance. The
default is false, disabling PAE support.
.TP
\fBuse_localtime\fR
Valid for the Xen HVM and KVM hypervisors.

A boolean option that specifies if the instance
should be started with its clock set to the
localtime of the machine (when true) or to the UTC
(When false). The default is false, which is useful
for Linux/Unix machines; for Windows OSes, it is
recommended to enable this parameter.
.TP
\fBkernel_path\fR
Valid for the Xen PVM and KVM hypervisors.

This option specifies the path (on the node) to the
kernel to boot the instance with. Xen PVM instances
always require this, while for KVM if this option is
empty, it will cause the machine to load the kernel
from its disks.
.TP
\fBkernel_args\fR
Valid for the Xen PVM and KVM hypervisors.

This options specifies extra arguments to the kernel
that will be loaded.  device. This is always used
for Xen PVM, while for KVM it is only used if the
\fBkernel_path\fR option is also
specified.

The default setting for this value is simply
"ro", which mounts the root
disk (initially) in read-only one. For example,
setting this to \fBsingle\fR will
cause the instance to start in single-user mode.
.TP
\fBinitrd_path\fR
Valid for the Xen PVM and KVM hypervisors.

This option specifies the path (on the node) to the
initrd to boot the instance with. Xen PVM instances
can use this always, while for KVM if this option is
only used if the \fBkernel_path\fR option
is also specified. You can pass here either an
absolute filename (the path to the initrd) if you
want to use an initrd, or use the format
\fBno_initrd_path\fR for no initrd.
.TP
\fBroot_path\fR
Valid for the Xen PVM and KVM hypervisors.

This options specifies the name of the root
device. This is always needed for Xen PVM, while for
KVM it is only used if the
\fBkernel_path\fR option is also
specified.
.TP
\fBserial_console\fR
Valid for the KVM hypervisor.

This boolean option specifies whether to
emulate a serial console for the instance.
.TP
\fBdisk_cache\fR
Valid for the KVM hypervisor.

The disk cache mode. It can be either
\fBdefault\fR to not pass any cache
option to KVM, or one of the KVM cache modes: none
(for direct I/O), writethrough (to use the host cache
but report completion to the guest only when the host
has committed the changes to disk) or writeback (to
use the host cache and report completion as soon as
the data is in the host cache). Note that there are
special considerations for the cache mode depending on
version of KVM used and disk type (always raw file
under Ganeti), please refer to the KVM documentation
for more details.
.TP
\fBsecurity_model\fR
Valid for the KVM hypervisor.

The security model for kvm. Currently one of
``none'', ``user'' or
``pool''\&. Under ``none'', the
default, nothing is done and instances are run as
the ganeti daemon user (normally root).

Under ``user'' kvm will drop
privileges and become the user specified by the
security_domain parameter.

Under ``pool'' a global cluster
pool of users will be used, making sure no two
instances share the same user on the same node.
(this mode is not implemented yet)
.TP
\fBsecurity_domain\fR
Valid for the KVM hypervisor.

Under security model ``user'' the username to
run the instance under. It must be a valid username
existing on the host.

Cannot be set under security model ``none''
or ``pool''\&.
.TP
\fBkvm_flag\fR
Valid for the KVM hypervisor.

If ``enabled'' the -enable-kvm flag is
passed to kvm. If ``disabled'' -disable-kvm is
passed. If unset no flag is passed, and the default running
mode for your kvm binary will be used.
.TP
\fBmigration_downtime\fR
Valid for the KVM hypervisor.

The maximum amount of time (in ms) a KVM instance is
allowed to be frozen during a live migration, in order to copy
dirty memory pages. Default value is 30ms, but you may need to
increase this value for busy instances.

This option is only effective with kvm versions >= 87
and qemu-kvm versions >= 0.11.0.
.TP
\fBuse_chroot\fR
Valid for the KVM hypervisor.

This boolean option determines wether to run the KVM
instance in a chroot directory.

If it is set to ``true'', an empty directory
is created before starting the instance and its path is passed via
the -chroot flag to kvm.
The directory is removed when the instance is stopped.

It is set to ``false'' by default.
.PP
The \fB--iallocator\fR option specifies the instance
allocator plugin to use. If you pass in this option the allocator
will select nodes for this instance automatically, so you don't need
to pass them with the \fB-n\fR option. For more
information please refer to the instance allocator documentation.
.PP
The \fB-t\fR options specifies the disk layout type for
the instance. The available choices are:
.TP
\fBdiskless\fR
This creates an instance with no disks. Its useful for
testing only (or other special cases).
.TP
\fBfile\fR
Disk devices will be regular files.
.TP
\fBplain\fR
Disk devices will be logical volumes.
.TP
\fBdrbd\fR
Disk devices will be drbd (version 8.x) on top of
lvm volumes.
.PP
The optional second value of the \fB--node\fR is used for
the drbd template type and specifies the remote node.
.PP
If you do not want gnt-instance to wait for the disk mirror
to be synced, use the \fB--no-wait-for-sync\fR
option.
.PP
The \fB--file-storage-dir\fR specifies the relative path
under the cluster-wide file storage directory to store file-based
disks. It is useful for having different subdirectories for
different instances. The full path of the directory where the disk
files are stored will consist of cluster-wide file storage directory
+ optional subdirectory + instance name. Example:
/srv/ganeti/file-storage/mysubdir/instance1.example.com. This option
is only relevant for instances using the file storage backend.
.PP
The \fB--file-driver\fR specifies the driver to use for
file-based disks. Note that currently these drivers work with the
xen hypervisor only. This option is only relevant for instances using
the file storage backend. The available choices are:
.TP
\fBloop\fR
Kernel loopback driver. This driver uses loopback
devices to access the filesystem within the
file. However, running I/O intensive applications in
your instance using the loop driver might result in
slowdowns.  Furthermore, if you use the loopback
driver consider increasing the maximum amount of
loopback devices (on most systems it's 8) using the
max_loop param.
.TP
\fBblktap\fR
The blktap driver (for Xen hypervisors). In
order to be able to use the blktap driver you should
check if the 'blktapctrl' user space disk agent is
running (usually automatically started via xend). This
user-level disk I/O interface has the advantage of
better performance. Especially if you use a network
file system (e.g. NFS) to store your instances this is
the recommended choice.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.PP
Example:

.nf
# gnt-instance add -t file --disk 0:size=30g -B memory=512 -o debian-etch \\
  -n node1.example.com --file-storage-dir=mysubdir instance1.example.com
# gnt-instance add -t plain --disk 0:size=30g -B memory=512 -o debian-etch \\
  -n node1.example.com instance1.example.com
# gnt-instance add -t drbd --disk 0:size=30g -B memory=512 -o debian-etch \\
  -n node1.example.com:node2.example.com instance2.example.com
          
.fi
.SS "BATCH-CREATE"

\fBbatch-create\fR \fBinstances_file.json\fR

.PP
This command (similar to the Ganeti 1.2
\fBbatcher\fR tool) submits multiple instance
creation jobs based on a definition file. The instance
configurations do not encompass all the possible options for
the \fBadd\fR command, but only a subset.
.PP
The instance file should be a valid-formed JSON file,
containing a dictionary with instance name and instance
parameters. The accepted parameters are:
.TP
\fBdisk_size\fR
The size of the disks of the instance.
.TP
\fBdisk_templace\fR
The disk template to use for the instance,
the same as in the \fBadd\fR
command.
.TP
\fBbackend\fR
A dictionary of backend parameters.
.TP
\fBhypervisor\fR
A dictionary with a single key (the
hypervisor name), and as value the hypervisor
options. If not passed, the default hypervisor and
hypervisor options will be inherited.
.TP
\fBmac, ip, mode, link\fR
Specifications for the one NIC that will be
created for the instance. 'bridge' is also accepted
as a backwards compatibile key.
.TP
\fBnics\fR
List of nics that will be created for the
instance. Each entry should be a dict, with mac, ip, mode
and link as possible keys. Please don't provide the "mac,
ip, mode, link" parent keys if you use this method for
specifying nics.
.TP
\fBprimary_node, secondary_node\fR
The primary and optionally the secondary node
to use for the instance (in case an iallocator script
is not used).
.TP
\fBiallocator\fR
Instead of specifying the nodes, an
iallocator script can be used to automatically compute
them.
.TP
\fBstart\fR
whether to start the instance
.TP
\fBip_check\fR
Skip the check for already-in-use instance;
see the description in the \fBadd\fR
command for details.
.TP
\fBname_check\fR
Skip the name check for instances;
see the description in the \fBadd\fR
command for details.
.TP
\fBfile_storage_dir, file_driver\fR
Configuration for the file
disk type, see the \fBadd\fR command for
details.
.PP
A simple definition for one instance can be (with most of
the parameters taken from the cluster defaults):

.nf
{
  "instance3": {
    "template": "drbd",
    "os": "debootstrap",
    "disk_size": ["25G"],
    "iallocator": "dumb"
  },
  "instance5": {
    "template": "drbd",
    "os": "debootstrap",
    "disk_size": ["25G"],
    "iallocator": "dumb",
    "hypervisor": "xen-hvm",
    "hvparams": {"acpi": true},
    "backend": {"memory": 512}
  }
}
.fi
.PP
The command will display the job id for each submitted instance, as follows:

.nf
# gnt-instance batch-create instances.json
instance3: 11224
instance5: 11225
.fi
.SS "REMOVE"

\fBremove\fR [ \fB--ignore-failures\fR ] [ \fB--shutdown-timeout=\fIN\fB\fR ] [ \fB--submit\fR ] \fB\fIinstance\fB\fR

.PP
Remove an instance. This will remove all data from the
instance and there is \fBno way back\fR\&. If
you are not sure if you use an instance again, use
\fBshutdown\fR first and leave it in the
shutdown state for a while.
.PP
The \fB--ignore-failures\fR option will cause the
removal to proceed even in the presence of errors during the
removal of the instance (e.g. during the shutdown or the
disk removal). If this option is not given, the command will
stop at the first error.
.PP
The \fB--shutdown-timeout\fR is used to specify how
much time to wait before forcing the shutdown (xm destroy in xen,
killing the kvm process, for kvm). By default two minutes are
given to each instance to stop.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.PP
Example:

.nf
# gnt-instance remove instance1.example.com
          
.fi
.SS "LIST"

\fBlist\fR [ \fB--no-headers\fR ] [ \fB--separator=\fISEPARATOR\fB\fR ] [ \fB-o \fI[+]FIELD,...\fB\fR ] [ \fB--roman\fR ] [ \fBinstance\fR\fI ...\fR ]

.PP
Shows the currently configured instances with memory usage,
disk usage, the node they are running on, and their run
status.
.PP
The \fB--no-headers\fR option will skip the
initial header line. The \fB--separator\fR option
takes an argument which denotes what will be used between
the output fields. Both these options are to help scripting.
.PP
The \fB--roman\fR option allows latin people to better
understand the cluster instances' status.
.PP
The \fB-o\fR option takes a comma-separated list
of output fields. The available fields and their meaning
are:
.TP
\fBname\fR
the instance name
.TP
\fBos\fR
the OS of the instance
.TP
\fBpnode\fR
the primary node of the instance
.TP
\fBsnodes\fR
comma-separated list of secondary nodes for the
instance; usually this will be just one node
.TP
\fBadmin_state\fR
the desired state of the instance (either "yes"
or "no" denoting the instance should run or
not)
.TP
\fBdisk_template\fR
the disk template of the instance
.TP
\fBoper_state\fR
the actual state of the instance; can be
one of the values "running", "stopped", "(node
down)"
.TP
\fBstatus\fR
combined form of admin_state and oper_stat;
this can be one of:
ERROR_nodedown if the
node of the instance is down,
ERROR_down if the
instance should run but is down,
ERROR_up if the
instance should be stopped but is actually running,
ADMIN_down if the
instance has been stopped (and is stopped) and
running if the
instance is set to be running (and is
running)
.TP
\fBoper_ram\fR
the actual memory usage of the instance as seen
by the hypervisor
.TP
\fBip\fR
the ip address ganeti recognizes as associated with
the first instance interface
.TP
\fBmac\fR
the first instance interface MAC address
.TP
\fBnic_mode\fR
the mode of the first instance NIC
(routed or bridged)
.TP
\fBnic_link\fR
the link of the first instance NIC
.TP
\fBsda_size\fR
the size of the instance's first disk
.TP
\fBsdb_size\fR
the size of the instance's second disk, if
any
.TP
\fBvcpus\fR
the number of VCPUs allocated to the
instance
.TP
\fBtags\fR
comma-separated list of the instances's
tags
.TP
\fBserial_no\fR
the so called 'serial number' of the
instance; this is a numeric field that is incremented
each time the instance is modified, and it can be used
to track modifications
.TP
\fBctime\fR
the creation time of the instance; note that this
field contains spaces and as such it's harder to
parse

if this attribute is not present (e.g. when
upgrading from older versions), then "N/A" will be
shown instead
.TP
\fBmtime\fR
the last modification time of the instance; note
that this field contains spaces and as such it's
harder to parse

if this attribute is not present (e.g. when
upgrading from older versions), then "N/A" will be
shown instead
.TP
\fBuuid\fR
Show the UUID of the instance (generated
automatically by Ganeti)
.TP
\fBnetwork_port\fR
If the instance has a network port assigned
to it (e.g. for VNC connections), this will be shown,
otherwise - will be
displayed.
.TP
\fBbeparams\fR
A text format of the entire beparams for the
instance. It's more useful to select individual fields
from this dictionary, see below.
.TP
\fBdisk.count\fR
The number of instance disks.
.TP
\fBdisk.size/N\fR
The size of the instance's Nth disk. This is
a more generic form of the sda_size
and sdb_size fields.
.TP
\fBdisk.sizes\fR
A comma-separated list of the disk sizes for
this instance.
.TP
\fBdisk_usage\fR
The total disk space used by this instance on
each of its nodes. This is not the instance-visible
disk size, but the actual disk "cost" of the
instance.
.TP
\fBnic.mac/N\fR
The MAC of the Nth instance NIC.
.TP
\fBnic.ip/N\fR
The IP address of the Nth instance NIC.
.TP
\fBnic.mode/N\fR
The mode of the Nth instance NIC
.TP
\fBnic.link/N\fR
The link of the Nth instance NIC
.TP
\fBnic.macs\fR
A comma-separated list of all the MACs of the
instance's NICs.
.TP
\fBnic.ips\fR
A comma-separated list of all the IP
addresses of the instance's NICs.
.TP
\fBnic.modes\fR
A comma-separated list of all the modes of the
instance's NICs.
.TP
\fBnic.links\fR
A comma-separated list of all the link parameters
of the instance's NICs.
.TP
\fBnic.count\fR
The number of instance nics.
.TP
\fBhv/\fINAME\fB\fR
The value of the hypervisor parameter called
\fINAME\fR\&. For details of what
hypervisor parameters exist and their meaning, see the
\fBadd\fR command.
.TP
\fBbe/memory\fR
The configured memory for the instance.
.TP
\fBbe/vcpus\fR
The configured number of VCPUs for the
instance.
.TP
\fBbe/auto_balance\fR
Whether the instance is considered in N+1
checks.
.PP
If the value of the option starts with the character
+, the new field(s) will be added to the
default list. This allows to quickly see the default list
plus a few other fields, instead of retyping the entire list
of fields.
.PP
There is a subtle grouping about the available output
fields: all fields except for \fBoper_state\fR,
\fBoper_ram\fR and \fBstatus\fR are
configuration value and not run-time values. So if you don't
select any of the these fields, the query will be satisfied
instantly from the cluster configuration, without having to
ask the remote nodes for the data. This can be helpful for
big clusters when you only want some data and it makes sense
to specify a reduced set of output fields.
.PP
The default output field list is:
name, os, pnode, admin_state, oper_state, oper_ram\&.
.SS "INFO"

\fBinfo\fR [ \fB-s\fR | \fB--static\fR ] [ \fB--roman\fR ] { \fB--all\fR | \fB\fIinstance\fB\fR\fI ...\fR }

.PP
Show detailed information about the given instance(s). This is
different from \fBlist\fR as it shows detailed data
about the instance's disks (especially useful for the drbd disk
template).
.PP
If the option \fB-s\fR is used, only information
available in the configuration file is returned, without
querying nodes, making the operation faster.
.PP
Use the \fB--all\fR to get info about all instances,
rather than explicitly passing the ones you're interested in.
.PP
The \fB--roman\fR option can be used to cause envy among
people who like ancient cultures, but are stuck with non-latin-friendly
cluster virtualization technologies.
.SS "MODIFY"

\fBmodify\fR
    [ \fB-H \fIHYPERVISOR_PARAMETERS\fB\fR ]
    [ \fB-B \fIBACKEND_PARAMETERS\fB\fR ]
    [ \fB--net add\fI[:options]\fB\fR | \fB--net remove\fR | \fB--net \fIN:options\fB\fR ]
    [ \fB--disk add:size=\fISIZE\fB\fR | \fB--disk remove\fR | \fB--disk \fIN\fB:mode=\fIMODE\fB\fR ]
    [ \fB-t { plain | drbd }\fR ]
    [ \fB--os-name=\fIOS\fB  [ --force-variant ]\fR ]
    [ \fB--submit\fR ]
    \fB\fIinstance\fB\fR

.PP
Modifies the memory size, number of vcpus, ip address, MAC
address and/or nic parameters for an instance. It can also
add and remove disks and NICs to/from the instance. Note
that you need to give at least one of the arguments, otherwise
the command complains.
.PP
The \fB-H\fR option specifies hypervisor options
in the form of \fBname=value[,...]\fR\&. For details which options can be specified, see the \fBadd\fR command.
.PP
The \fB-t\fR option will change the disk template
of the instance. Currently only conversions between the
plain and drbd disk templates are supported, and the
instance must be stopped before attempting the conversion.
.PP
The \fB--disk
add:size=\fISIZE\fB\fR option
adds a disk to the instance. The \fB--disk
remove\fR will remove the last disk of the
instance. The \fB--disk
\fIN\fB:mode=\fIMODE\fB\fR
option will change the mode of the Nth disk of the instance
between read-only (ro) and read-write
(rw).
.PP
The \fB--net
add:\fIoptions\fB\fR option will
add a new NIC to the instance. The available options are the
same as in the \fBadd\fR command (mac, ip, link,
mode). The \fB--net remove\fR will remove the
last NIC of the instance, while the \fB--net
\fIN\fB:\fIoptions\fB\fR
option will change the parameters of the Nth instance NIC.
.PP
The option \fB--os-name\fR will change the OS
name for the instance (without reinstallation). In case an
OS variant is specified that is not found, then by default
the modification is refused,
unless \fB--force-variant\fR is passed. An
invalid OS will also be refused, unless
the \fB--force\fR option is given.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.PP
All the changes take effect at the next restart. If the
instance is running, there is no effect on the instance.
.SS "REINSTALL"

\fBreinstall\fR [ \fB-o \fIos-type\fB\fR ] [ \fB--select-os\fR ] [ \fB-f \fIforce\fB\fR ] [ \fB--force-multiple\fR ]
    [ \fB--instance\fR | \fB--node\fR | \fB--primary\fR | \fB--secondary\fR | \fB--all\fR ] [ \fB--submit\fR ] [ \fB\fIinstance\fB\fR\fI ...\fR ]

.PP
Reinstalls the operating system on the given instance(s). The
instance(s) must be stopped when running this command. If the
\fB--os-type\fR is specified, the operating
system is changed.
.PP
The \fB--select-os\fR option switches to an
interactive OS reinstall. The user is prompted to select the OS
template from the list of available OS templates.
.PP
Since this is a potentially dangerous command, the user will
be required to confirm this action, unless the
\fB-f\fR flag is passed. When multiple instances
are selected (either by passing multiple arguments or by
using the \fB--node\fR,
\fB--primary\fR, \fB--secondary\fR or
\fB--all\fR options), the user must pass both the
\fB--force\fR and
\fB--force-multiple\fR options to skip the
interactive confirmation.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.SS "RENAME"

\fBrename\fR [ \fB--no-ip-check\fR ] [ \fB--submit\fR ] \fB\fIinstance\fB\fR \fB\fInew_name\fB\fR

.PP
Renames the given instance. The instance must be stopped
when running this command. The requirements for the new name
are the same as for adding an instance: the new name must be
resolvable and the IP it resolves to must not be reachable
(in order to prevent duplicate IPs the next time the
instance is started). The IP test can be skipped if the
\fB--no-ip-check\fR option is passed.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.SS "STARTING/STOPPING/CONNECTING TO CONSOLE"
.SS "STARTUP"

\fBstartup\fR
    [ \fB--force\fR ]
    [ \fB--force-multiple\fR ]
    [ \fB--instance\fR | \fB--node\fR | \fB--primary\fR | \fB--secondary\fR | \fB--all\fR | \fB--tags\fR | \fB--node-tags\fR | \fB--pri-node-tags\fR | \fB--sec-node-tags\fR ]
    [ \fB-H key=value...\fR ] [ \fB-B key=value...\fR ]
    [ \fB--submit\fR ]
    [ \fB\fIname\fB\fR\fI ...\fR ]

.PP
Starts one or more instances, depending on the following
options. The four available modes are:
.TP
\fB--instance\fR
will start the instances given as arguments
(at least one argument required); this is the default
selection
.TP
\fB--node\fR
will start the instances who have the given
node as either primary or secondary
.TP
\fB--primary\fR
will start all instances whose primary node
is in the list of nodes passed as arguments (at least
one node required)
.TP
\fB--secondary\fR
will start all instances whose secondary node
is in the list of nodes passed as arguments (at least
one node required)
.TP
\fB--all\fR
will start all instances in the cluster (no
arguments accepted)
.TP
\fB--tags\fR
will start all instances in the cluster with
the tags given as arguments
.TP
\fB--node-tags\fR
will start all instances in the cluster on
nodes with the tags given as arguments
.TP
\fB--pri-node-tags\fR
will start all instances in the cluster on
primary nodes with the tags given as
arguments
.TP
\fB--sec-node-tags\fR
will start all instances in the cluster on
secondary nodes with the tags given as
arguments
.PP
Note that although you can pass more than one selection
option, the last one wins, so in order to guarantee the
desired result, don't pass more than one such option.
.PP
Use \fB--force\fR to start even if secondary disks are
failing.
.PP
The \fB--force-multiple\fR will skip the
interactive confirmation in the case the more than one
instance will be affected.
.PP
The \fB-H\fR and \fB-B\fR options
specify temporary hypervisor and backend parameters that can
be used to start an instance with modified parameters. They
can be useful for quick testing without having to modify an
instance back and forth, e.g.:

.nf
# gnt-instance start -H root_args="single" instance1
# gnt-instance start -B memory=2048 instance2
          
.fi
The first form will start the instance
\fBinstance1\fR in single-user mode, and
the instance \fBinstance2\fR with 2GB of
RAM (this time only, unless that is the actual instance
memory size already). Note that the values override the
instance parameters (and not extend them): an instance with
"root_args=ro" when started with \fB-H
root_args=single\fR will result in "single", not
"ro single".
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.PP
Example:

.nf
# gnt-instance start instance1.example.com
# gnt-instance start --node node1.example.com node2.example.com
# gnt-instance start --all
          
.fi
.SS "SHUTDOWN"

\fBshutdown\fR
    [ \fB--timeout=\fIN\fB\fR ]
    [ \fB--force-multiple\fR ]
    [ \fB--instance\fR | \fB--node\fR | \fB--primary\fR | \fB--secondary\fR | \fB--all\fR | \fB--tags\fR | \fB--node-tags\fR | \fB--pri-node-tags\fR | \fB--sec-node-tags\fR ]
    [ \fB--submit\fR ]
    [ \fB\fIname\fB\fR\fI ...\fR ]

.PP
Stops one or more instances. If the instance cannot be
cleanly stopped during a hardcoded interval (currently 2
minutes), it will forcibly stop the instance (equivalent to
switching off the power on a physical machine).
.PP
The \fB--timeout\fR is used to specify how much time to
wait before forcing the shutdown (xm destroy in xen, killing the kvm
process, for kvm). By default two minutes are given to each instance
to stop.
.PP
The \fB--instance\fR, \fB--node\fR,
\fB--primary\fR, \fB--secondary\fR,
\fB--all\fR, \fB--tags\fR,
\fB--node-tags\fR, \fB--pri-node-tags\fR and
\fB--sec-node-tags\fR options are similar as for the
\fBstartup\fR command and they influence the
actual instances being shutdown.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.PP
Example:

.nf
# gnt-instance shutdown instance1.example.com
# gnt-instance shutdown --all
          
.fi
.SS "REBOOT"

\fBreboot\fR
    [ \fB--type=\fIREBOOT-TYPE\fB\fR ]
    [ \fB--ignore-secondaries\fR ]
    [ \fB--shutdown-timeout=\fIN\fB\fR ]
    [ \fB--force-multiple\fR ]
    [ \fB--instance\fR | \fB--node\fR | \fB--primary\fR | \fB--secondary\fR | \fB--all\fR | \fB--tags\fR | \fB--node-tags\fR | \fB--pri-node-tags\fR | \fB--sec-node-tags\fR ]
    [ \fB--submit\fR ]
    [ \fB\fIname\fB\fR\fI ...\fR ]

.PP
Reboots one or more instances. The type of reboot depends on
the value of \fB--type\fR\&. A soft reboot does a
hypervisor reboot, a hard reboot does a instance stop,
recreates the hypervisor config for the instance and
starts the instance. A full reboot does the equivalent
of \fBgnt-instance shutdown && gnt-instance
startup\fR\&. The default is hard reboot.
.PP
For the hard reboot the option
\fB--ignore-secondaries\fR ignores errors for the
secondary node while re-assembling the instance disks.
.PP
The \fB--instance\fR, \fB--node\fR,
\fB--primary\fR, \fB--secondary\fR,
\fB--all\fR, \fB--tags\fR,
\fB--node-tags\fR, \fB--pri-node-tags\fR and
\fB--sec-node-tags\fR options are similar as for the
\fBstartup\fR command and they influence the
actual instances being rebooted.
.PP
The \fB--shutdown-timeout\fR is used to specify how
much time to wait before forcing the shutdown (xm destroy in xen,
killing the kvm process, for kvm). By default two minutes are
given to each instance to stop.
.PP
The \fB--force-multiple\fR will skip the
interactive confirmation in the case the more than one
instance will be affected.
.PP
Example:

.nf
# gnt-instance reboot instance1.example.com
# gnt-instance reboot --type=full instance1.example.com
          
.fi
.SS "CONSOLE"

\fBconsole\fR [ \fB--show-cmd\fR ] \fB\fIinstance\fB\fR

.PP
Connects to the console of the given instance. If the
instance is not up, an error is returned. Use the
\fB--show-cmd\fR option to display the command
instead of executing it.
.PP
For HVM instances, this will attempt to connect to the
serial console of the instance. To connect to the
virtualized "physical" console of a HVM instance, use a VNC
client with the connection info from the
\fBinfo\fR command.
.PP
Example:

.nf
# gnt-instance console instance1.example.com
          
.fi
.SS "DISK MANAGEMENT"
.SS "REPLACE-DISKS"

\fBreplace-disks\fR [ \fB--submit\fR ] [ \fB--early-release\fR ] \fB-p\fR [ \fB--disks \fIidx\fB\fR ] \fB\fIinstance\fB\fR


\fBreplace-disks\fR [ \fB--submit\fR ] [ \fB--early-release\fR ] \fB-s\fR [ \fB--disks \fIidx\fB\fR ] \fB\fIinstance\fB\fR


\fBreplace-disks\fR [ \fB--submit\fR ] [ \fB--early-release\fR ] { \fB--iallocator \fIname\fB\fR | \fB--new-secondary \fINODE\fB\fR } \fB\fIinstance\fB\fR


\fBreplace-disks\fR [ \fB--submit\fR ] [ \fB--early-release\fR ] \fB--auto\fR \fB\fIinstance\fB\fR

.PP
This command is a generalized form for replacing disks. It
is currently only valid for the mirrored (DRBD) disk
template.
.PP
The first form (when passing the \fB-p\fR option)
will replace the disks on the primary, while the second form
(when passing the \fB-s\fR option will replace
the disks on the secondary node. For these two cases (as the
node doesn't change), it is possible to only run the replace
for a subset of the disks, using the option
\fB--disks\fR which takes a list of
comma-delimited disk indices (zero-based),
e.g. \fB0,2\fR to replace only the first
and third disks.
.PP
The third form (when passing either the
\fB--iallocator\fR or the
\fB--new-secondary\fR option) is designed to
change secondary node of the instance.  Specifying
\fB--iallocator\fR makes the new secondary be
selected automatically by the specified allocator plugin,
otherwise the new secondary node will be the one chosen
manually via the \fB--new-secondary\fR option.
.PP
The fourth form (when using \fB--auto\fR) will
automatically determine which disks of an instance are faulty and
replace them within the same node. The \fB--auto\fR
option works only when an instance has only faulty disks on
either the primary or secondary node; it doesn't work when
both sides have faulty disks.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.PP
The \fB--early-release\fR changes the code so
that the old storage on secondary node(s) is removed early
(before the resync is completed) and the internal Ganeti
locks for the current (and new, if any) secondary node are
also released, thus allowing more parallelism in the cluster
operation. This should be used only when recovering from a
disk failure on the current secondary (thus the old storage
is already broken) or when the storage on the primary node
is known to be fine (thus we won't need the old storage for
potential recovery).
.PP
Note that it is not possible to select an offline or drained
node as a new secondary.
.SS "ACTIVATE-DISKS"

\fBactivate-disks\fR [ \fB--submit\fR ] [ \fB--ignore-size\fR ] \fB\fIinstance\fB\fR

.PP
Activates the block devices of the given instance. If
successful, the command will show the location and name of
the block devices:

.nf
node1.example.com:disk/0:/dev/drbd0
node1.example.com:disk/1:/dev/drbd1
          
.fi
In this example, \fBnode1.example.com\fR is
the name of the node on which the devices have been
activated. The \fBdisk/0\fR and
\fBdisk/1\fR are the Ganeti-names of the
instance disks; how they are visible inside the instance is
hypervisor-specific. \fB/dev/drbd0\fR and
\fB/dev/drbd1\fR are the actual block devices
as visible on the node.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.PP
The \fB--ignore-size\fR option can be used to
activate disks ignoring the currently configured size in
Ganeti. This can be used in cases where the configuration
has gotten out of sync with the real-world (e.g. after a
partially-failed grow-disk operation or due to rounding in
LVM devices). This should not be used in normal cases, but
only when activate-disks fails without it.
.PP
Note that it is safe to run this command while the instance
is already running.
.SS "DEACTIVATE-DISKS"

\fBdeactivate-disks\fR [ \fB--submit\fR ] \fB\fIinstance\fB\fR

.PP
De-activates the block devices of the given instance. Note
that if you run this command for an instance with a drbd
disk template, while it is running, it will not be able to
shutdown the block devices on the primary node, but it will
shutdown the block devices on the secondary nodes, thus
breaking the replication.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.SS "GROW-DISK"

\fBgrow-disk\fR [ \fB--no-wait-for-sync\fR ] [ \fB--submit\fR ] \fB\fIinstance\fB\fR \fB\fIdisk\fB\fR \fB\fIamount\fB\fR

.PP
Grows an instance's disk. This is only possible for
instances having a plain or
drbd disk template.
.PP
Note that this command only change the block device size; it
will not grow the actual filesystems, partitions, etc. that
live on that disk. Usually, you will need to:
.TP 3
1. 
use \fBgnt-instance grow-disk\fR
.TP 3
2. 
reboot the instance (later, at a convenient
time)
.TP 3
3. 
use a filesystem resizer, such as
\fBext2online\fR(8) or
\fBxfs_growfs\fR(8) to resize the
filesystem, or use \fBfdisk\fR(8) to change the
partition table on the disk
.PP
The \fIdisk\fR argument is the index of
the instance disk to grow. The
\fIamount\fR argument is given either
as a number (and it represents the amount to increase the
disk with in mebibytes) or can be given similar to the
arguments in the create instance operation, with a suffix
denoting the unit.
.PP
Note that the disk grow operation might complete on one node
but fail on the other; this will leave the instance with
different-sized LVs on the two nodes, but this will not
create problems (except for unused space).
.PP
If you do not want gnt-instance to wait for the new disk
region to be synced, use the
\fB--no-wait-for-sync\fR option.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.PP
Example (increase the first disk for instance1 by 16GiB):

.nf
# gnt-instance grow-disk instance1.example.com 0 16g
          
.fi
.PP
Also note that disk shrinking is not supported; use
\fBgnt-backup export\fR and then
\fBgnt-backup import\fR to reduce the disk size
of an instance.
.SS "RECREATE-DISKS"

\fBrecreate-disks\fR [ \fB--submit\fR ] [ \fB--disks=indices\fR ] \fB\fIinstance\fB\fR

.PP
Recreates the disks of the given instance, or only a subset
of the disks (if the option \fBdisks\fR is
passed, which must be a comma-separated list of disk
indices, starting from zero).
.PP
Note that this functionality should only be used for missing
disks; if any of the given disks already exists, the
operation will fail. While this is suboptimal,
recreate-disks should hopefully not be needed in normal
operation and as such the impact of this is low.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.SS "RECOVERY"
.SS "FAILOVER"

\fBfailover\fR [ \fB-f\fR ] [ \fB--ignore-consistency\fR ] [ \fB--shutdown-timeout=\fIN\fB\fR ] [ \fB--submit\fR ] \fB\fIinstance\fB\fR

.PP
Failover will fail the instance over its secondary
node. This works only for instances having a drbd disk
template.
.PP
Normally the failover will check the consistency of the
disks before failing over the instance. If you are trying to
migrate instances off a dead node, this will fail. Use the
\fB--ignore-consistency\fR option for this
purpose. Note that this option can be dangerous as errors in
shutting down the instance will be ignored, resulting in
possibly having the instance running on two machines in
parallel (on disconnected DRBD drives).
.PP
The \fB--shutdown-timeout\fR is used to specify how
much time to wait before forcing the shutdown (xm destroy in xen,
killing the kvm process, for kvm). By default two minutes are
given to each instance to stop.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.PP
Example:

.nf
# gnt-instance failover instance1.example.com
          
.fi
.SS "MIGRATE"

\fBmigrate\fR [ \fB-f\fR ] \fB--cleanup\fR \fB\fIinstance\fB\fR


\fBmigrate\fR [ \fB-f\fR ] [ \fB--non-live\fR ] \fB\fIinstance\fB\fR

.PP
Migrate will move the instance to its secondary node without
shutdown. It only works for instances having the drbd8 disk
template type.
.PP
The migration command needs a perfectly healthy instance, as
we rely on the dual-master capability of drbd8 and the disks
of the instance are not allowed to be degraded.
.PP
The \fB--non-live\fR option will switch (for the
hypervisors that support it) between a "fully live"
(i.e. the interruption is as minimal as possible) migration
and one in which the instance is frozen, its state saved and
transported to the remote node, and then resumed there. This
all depends on the hypervisor support for two different
methods. In any case, it is not an error to pass this
parameter (it will just be ignored if the hypervisor doesn't
support it).
.PP
If the \fB--cleanup\fR option is passed, the
operation changes from migration to attempting recovery from
a failed previous migration. In this mode, ganeti checks if
the instance runs on the correct node (and updates its
configuration if not) and ensures the instances's disks are
configured correctly. In this mode, the
\fB--non-live\fR option is ignored.
.PP
The option \fB-f\fR will skip the prompting for
confirmation.
.PP
Example (and expected output):

.nf
# gnt-instance migrate instance1
Migrate will happen to the instance instance1. Note that migration is
**experimental** in this version. This might impact the instance if
anything goes wrong. Continue?
y/[n]/?: y
* checking disk consistency between source and target
* ensuring the target is in secondary mode
* changing disks into dual-master mode
 - INFO: Waiting for instance instance1 to sync disks.
 - INFO: Instance instance1's disks are in sync.
* migrating instance to node2.example.com
* changing the instance's disks on source node to secondary
 - INFO: Waiting for instance instance1 to sync disks.
 - INFO: Instance instance1's disks are in sync.
* changing the instance's disks to single-master
#
          
.fi
.SS "MOVE"

\fBmove\fR [ \fB-f\fR ] [ \fB-n \fInode\fB\fR ] [ \fB--shutdown-timeout=\fIN\fB\fR ] [ \fB--submit\fR ] \fB\fIinstance\fB\fR

.PP
Move will move the instance to an arbitrary node in the
cluster. This works only for instances having a plain or
file disk template.
.PP
Note that since this operation is done via data copy, it
will take a long time for big disks (similar to
replace-disks for a drbd instance).
.PP
The \fB--shutdown-timeout\fR is used to specify how
much time to wait before forcing the shutdown (xm destroy in xen,
killing the kvm process, for kvm). By default two minutes are
given to each instance to stop.
.PP
The \fB--submit\fR option is used to send the job to
the master daemon but not wait for its completion. The job
ID will be shown so that it can be examined via
\fBgnt-job info\fR\&.
.PP
Example:

.nf
# gnt-instance move -n node3.example.com instance1.example.com
          
.fi
.SS "TAGS"
.SS "ADD-TAGS"

\fBadd-tags\fR [ \fB--from \fIfile\fB\fR ] \fB\fIinstancename\fB\fR \fB\fItag\fB\fR\fI ...\fR

.PP
Add tags to the given instance. If any of the tags contains
invalid characters, the entire operation will abort.
.PP
If the \fB--from\fR option is given, the list of
tags will be extended with the contents of that file (each
line becomes a tag). In this case, there is not need to pass
tags on the command line (if you do, both sources will be
used). A file name of - will be interpreted as stdin.
.SS "LIST-TAGS"

\fBlist-tags\fR \fB\fIinstancename\fB\fR

.PP
List the tags of the given instance.
.SS "REMOVE-TAGS"

\fBremove-tags\fR [ \fB--from \fIfile\fB\fR ] \fB\fIinstancename\fB\fR \fB\fItag\fB\fR\fI ...\fR

.PP
Remove tags from the given instance. If any of the tags are
not existing on the node, the entire operation will abort.
.PP
If the \fB--from\fR option is given, the list of
tags will be extended with the contents of that file (each
line becomes a tag). In this case, there is not need to pass
tags on the command line (if you do, both sources will be
used). A file name of - will be interpreted as stdin.
.SH "REPORTING BUGS"
.PP
Report bugs to  <URL:http://code.google.com/p/ganeti/> or contact the
developers using the ganeti mailing list
<ganeti@googlegroups.com>\&.
.SH "SEE ALSO"
.PP
Ganeti overview and specifications:
\fBganeti\fR(7) (general overview),
\fBganeti-os-interface\fR(7) (guest OS definitions).
.PP
Ganeti commands:
\fBgnt-cluster\fR(8) (cluster-wide commands),
\fBgnt-job\fR(8) (job-related commands),
\fBgnt-node\fR(8) (node-related commands),
\fBgnt-instance\fR(8) (instance commands),
\fBgnt-os\fR(8) (guest OS commands),
\fBgnt-backup\fR(8) (instance import/export commands),
\fBgnt-debug\fR(8) (debug commands).
.PP
Ganeti daemons:
\fBganeti-watcher\fR(8) (automatic instance restarter),
\fBganeti-cleaner\fR(8) (job queue cleaner),
\fBganeti-noded\fR(8) (node daemon),
\fBganeti-masterd\fR(8) (master daemon),
\fBganeti-rapi\fR(8) (remote API daemon).
.SH "COPYRIGHT"
.PP
Copyright (C) 2006, 2007, 2008, 2009 Google Inc. Permission is
granted to copy, distribute and/or modify under the terms of the
GNU General Public License as published by the Free Software
Foundation; either version 2 of the License, or (at your option)
any later version.
.PP
On Debian systems, the complete text of the GNU General Public
License can be found in /usr/share/common-licenses/GPL.
